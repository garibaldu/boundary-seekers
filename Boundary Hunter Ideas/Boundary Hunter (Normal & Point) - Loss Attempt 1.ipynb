{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from autograd import grad\n",
    "\n",
    "def generateChevronData():\n",
    "    xBounds = [-50, 50]\n",
    "    yBounds = [-50, 50]\n",
    "    totalPoints = 100\n",
    "    \n",
    "    points = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, totalPoints):\n",
    "        x = random.randint(xBounds[0], xBounds[1])\n",
    "        y = random.randint(yBounds[0], yBounds[1])\n",
    "        \n",
    "        if x >= y and x <= -y:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(1)\n",
    "        \n",
    "    return np.array(points), np.array(targets)\n",
    "    \n",
    "def plotScatter(points):\n",
    "    xs = [x[0] for x in points]\n",
    "    ys = [y[1] for y in points]\n",
    "    \n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    return 1.0/(1.0 + np.exp(-phi))\n",
    "\n",
    "def loss(weights):\n",
    "    predictions = logisticPrediction(weights, points)\n",
    "#     print(predictions)\n",
    "    w = np.full((len(predictions)), np.log(1/2)) # CONSTANT\n",
    "    r = responsibility(weights, points)\n",
    "#     print(r)\n",
    "    return -(1/len(points)) * np.sum( r * ((targets*np.log(predictions) + (1-targets)*np.log(1-predictions))) + (1-r) * w)\n",
    "\n",
    "def logisticPrediction(weights, p):\n",
    "    return np.array(list(map(lambda x: predict(weights, x), p))) \n",
    "    \n",
    "def predict(weights, inputs):\n",
    "    n = np.array([weights[0], weights[1]])\n",
    "    i = np.array([weights[2] - inputs[0], weights[3] - inputs[1]])\n",
    "    return sigmoid(np.dot(n, i))\n",
    "\n",
    "def responsibility(weights, points):\n",
    "    r = weights[4]\n",
    "    a = np.array([weights[2], weights[3]])\n",
    "    \n",
    "    dif = np.array(list(map(lambda x: x - a, points)))\n",
    "    s = np.array(list(map(lambda x: np.sum(np.power(x, 2)), dif)))\n",
    "    d = np.sqrt(s)\n",
    "#     print(d)\n",
    "    t = 1-f(d, r)\n",
    "#     print(t)\n",
    "\n",
    "    return t\n",
    "\n",
    "def f(d, r):\n",
    "    return 1/(1 + np.power(np.e, 10*(d-r)))\n",
    "#     return np.power(np.e, -(1.0/15.0) * np.power(d/r, 2))\n",
    "#     return np.maximum(d - r, 0)/(np.abs(d - r) + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainBoundaryHunter():\n",
    "    weights = np.array([0.0, 0.0, 0.0, 0.0, 0.3])\n",
    "    gradient = grad(loss)\n",
    "    print(\"Initial Loss: \", loss(weights))\n",
    "    for i in range(0, 10000):\n",
    "        g = gradient(weights)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss [i = \" + str(i) + \"]: \" + str(loss(weights)))\n",
    "            print(weights)\n",
    "            checkGrad(0.00001, 0.0001, weights, g)\n",
    "        \n",
    "        weights -= 0.01 * g\n",
    "        if weights[4] < 0:\n",
    "            weights[4] = 0\n",
    "            \n",
    "    print(\"Trained Loss: \", loss(weights))    \n",
    "    print(\"Weights: \", weights)\n",
    "    return weights\n",
    "\n",
    "def checkGrad(pterb, threshold, weights, g):\n",
    "    grad = np.zeros(len(weights))\n",
    "    for i in range(0, len(weights)):\n",
    "        p = np.zeros(len(weights))\n",
    "        p[i] = pterb\n",
    "        \n",
    "        lossBefore = loss(weights)\n",
    "        lossAfter = loss(weights + p)\n",
    "        \n",
    "        grad[i] = (lossAfter - lossBefore)/pterb\n",
    "        \n",
    "\n",
    "    return grad\n",
    "\n",
    "    dif = np.absolute(computedGrad - grad)\n",
    "    for d in dif:\n",
    "        if d > threshold:\n",
    "            print(\"ERROR\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0:  35\n",
      "Type 1:  65\n",
      "Initial Loss:  0.69314718056\n",
      "Loss [i = 0]: 0.69314718056\n",
      "[ 0.   0.   0.   0.   0.3]\n",
      "Loss [i = 1000]: 0.429093201385\n",
      "[-0.19389319 -1.44336635 -0.07051311 -0.6069304   0.15767451]\n",
      "Loss [i = 2000]: 0.359458396653\n",
      "[-0.33596171 -2.2479842  -0.02941794 -0.52377503  0.09950072]\n",
      "Loss [i = 3000]: 0.326236654906\n",
      "[-0.4549366  -2.80489248 -0.02159592 -0.48388116  0.04298017]\n",
      "Loss [i = 4000]: 0.307754191004\n",
      "[-0.55313997 -3.22068297 -0.0285389  -0.46659538  0.01241527]\n",
      "Loss [i = 5000]: 0.296227489067\n",
      "[-0.63596893 -3.54863013 -0.03819847 -0.45639301  0.        ]\n",
      "Loss [i = 6000]: 0.288471061794\n",
      "[-0.70721344 -3.81723085 -0.04763867 -0.44959727  0.        ]\n",
      "Loss [i = 7000]: 0.282959997423\n",
      "[-0.7694494  -4.04313344 -0.05586093 -0.44464486  0.        ]\n",
      "Loss [i = 8000]: 0.278891500437\n",
      "[-0.82446593 -4.23686345 -0.06262778 -0.44089727  0.        ]\n",
      "Loss [i = 9000]: 0.275798865677\n",
      "[-0.87354898 -4.40549903 -0.06799267 -0.43800252  0.        ]\n",
      "Trained Loss:  0.273393278159\n",
      "Weights:  [-0.91765732 -4.55402639 -0.07213061 -0.43573916  0.        ]\n",
      "\n",
      "[ 2.05055883  0.91765732  4.55402639]\n",
      "\n",
      "Line\n",
      "B: -0.450273813535\n",
      "XCoef: -0.201504610731\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b38d76ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "points, targets = generateChevronData()\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "\n",
    "# Plot points on graph\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    if targets[i] == 0:\n",
    "        c1.append(points[i])\n",
    "    else:\n",
    "        c2.append(points[i])\n",
    "\n",
    "print(\"Type 0: \", len(c1))\n",
    "print(\"Type 1: \", len(c2))\n",
    "        \n",
    "plotScatter(c1)\n",
    "plotScatter(c2)\n",
    "\n",
    "weights = trainBoundaryHunter()\n",
    "\n",
    "plt.scatter(weights[2], weights[3])\n",
    "\n",
    "n = np.array([weights[0] * weights[2] + weights[1] * weights[3], \n",
    "              -weights[0], \n",
    "              -weights[1]])\n",
    "\n",
    "byas = -1 * n[0]/n[2]\n",
    "Xcoef = -1 * n[1]/n[2]\n",
    "\n",
    "x = np.linspace(-1.5, 1.5, 500)\n",
    "y = np.linspace(-1.5, 1.5, 500)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "F = ((X - weights[2]))**2 + ((Y - weights[3]))**2 - weights[4]**2\n",
    "plt.contour(X,Y,F,[0])\n",
    "\n",
    "print()\n",
    "print(n)\n",
    "print(\"\\nLine\")\n",
    "print(\"B: \" + str(byas))\n",
    "print(\"XCoef: \" + str(Xcoef))\n",
    "\n",
    "plt.plot([-1.0, 1.0], [-1*Xcoef + byas, Xcoef + byas], 'k-')\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
