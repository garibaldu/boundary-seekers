{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from autograd import grad\n",
    "\n",
    "def generateChevronData():\n",
    "    xBounds = [-50, 50]\n",
    "    yBounds = [-50, 50]\n",
    "    totalPoints = 100\n",
    "    \n",
    "    points = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, totalPoints):\n",
    "        x = random.randint(xBounds[0], xBounds[1])\n",
    "        y = random.randint(yBounds[0], yBounds[1])\n",
    "        \n",
    "        if x >= y and x <= -y:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(1)\n",
    "        \n",
    "    return np.array(points), np.array(targets)\n",
    "    \n",
    "def plotScatter(points):\n",
    "    xs = [x[0] for x in points]\n",
    "    ys = [y[1] for y in points]\n",
    "    \n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    return 1.0/(1.0 + np.exp(-phi))\n",
    "\n",
    "def loss(weights):\n",
    "    predictions = logisticPrediction(weights, points)\n",
    "    crossEntropy = (targets*np.log(predictions) + (1-targets)*np.log(1-predictions))\n",
    "    r = responsibility(weights, points)\n",
    "    notLocal = list(map(lambda x: not (r[x] == 1.0),range(0, len(points))))\n",
    "    \n",
    "    nonLocalPoints = np.array([points[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "    nonLocalTargets = np.array([targets[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "    nonLocalPredictions = np.array([predictions[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "    nonLocalR = np.array([r[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "\n",
    "    \n",
    "    invCrossEntropy = nonLocalTargets * (np.log(1-nonLocalPredictions)) + (1-nonLocalTargets)*(np.log(nonLocalPredictions))\n",
    "    \n",
    "    return -(((1/len(points)) * np.sum( r * crossEntropy )) + ((1/len(nonLocalPoints)) * np.sum(nonLocalR * invCrossEntropy)))\n",
    "\n",
    "def logisticPrediction(weights, p):\n",
    "    return np.array(list(map(lambda x: predict(weights, x), p))) \n",
    "    \n",
    "def predict(weights, inputs):\n",
    "    n = np.array([weights[0], weights[1]])\n",
    "    i = np.array([weights[2] - inputs[0], weights[3] - inputs[1]])\n",
    "    return sigmoid(np.dot(n, i))\n",
    "\n",
    "def responsibility(weights, points):\n",
    "    r = np.absolute(weights[4])\n",
    "    a = np.array([weights[2], weights[3]])\n",
    "    \n",
    "    dif = np.array(list(map(lambda x: x - a, points)))\n",
    "    s = np.array(list(map(lambda x: np.sum(np.power(x, 2)), dif)))\n",
    "    d = np.sqrt(s)\n",
    "\n",
    "    t = 1 - f(d, r)\n",
    "    return t\n",
    "\n",
    "def f(d, r):\n",
    "    return np.maximum(d - np.absolute(r), 0)/(np.abs(d - np.absolute(r)) + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainBoundaryHunter():\n",
    "    weights = np.array([0.0, 0.0, 0.0, 0.0, 0.3])\n",
    "    gradient = grad(loss)\n",
    "    print(\"Initial Loss: \", loss(weights))\n",
    "    for i in range(0, 10000):\n",
    "        g = gradient(weights)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss [i = \" + str(i) + \"]: \" + str(loss(weights)))\n",
    "            print(weights)\n",
    "            checkGrad(0.00001, 0.0001, weights, g)\n",
    "        \n",
    "#         weights = computeStep(weights)\n",
    "        weights -= 0.001 * g\n",
    "            \n",
    "    print(\"Trained Loss: \", loss(weights))    \n",
    "    print(\"Weights: \", weights)\n",
    "    return weights\n",
    "\n",
    "def checkGrad(pterb, threshold, weights, g):\n",
    "    grad = np.zeros(len(weights))\n",
    "    for i in range(0, len(weights)):\n",
    "        p = np.zeros(len(weights))\n",
    "        p[i] = pterb\n",
    "        \n",
    "        lossBefore = loss(weights)\n",
    "        lossAfter = loss(weights + p)\n",
    "        \n",
    "        grad[i] = (lossAfter - lossBefore)/pterb\n",
    "        \n",
    "\n",
    "    return grad\n",
    "\n",
    "    dif = np.absolute(computedGrad - grad)\n",
    "    for d in dif:\n",
    "        if d > threshold:\n",
    "            print(\"ERROR\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0:  35\n",
      "Type 1:  65\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "Initial Loss:  0.313880458094\n",
      "Autograd ArrayNode with value [ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387] and 1 progenitors(s)\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "Loss [i = 0]: 0.313880458094\n",
      "[ 0.   0.   0.   0.   0.3]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "[ 0.98730968  1.23223959  0.91586877  1.15603564  1.10344225  1.22442444\n",
      "  0.41231299  1.34358446  1.38621066  0.65115467  0.62031315  0.58820813\n",
      "  0.99639972  0.98184052  1.21606513  0.36877419  0.92195857  0.79648352\n",
      "  0.85906717  0.88813828  0.83571263  1.01999529  0.52802121  1.05603826\n",
      "  0.32558378  0.33526408  0.7615823   0.52498571  0.77819869  1.00579282\n",
      "  1.29321939  0.65969933  0.82461142  0.68116547  1.05395047  0.96042511\n",
      "  0.65390733  0.92131232  0.78816826  0.94763854  1.199992    0.72470215\n",
      "  0.73374791  0.91410984  0.30593921  1.12800106  0.6449893   0.66484013\n",
      "  1.15966047  0.91782155  0.44044432  0.9476187   0.29528766  0.51263086\n",
      "  0.92195228  1.0197941   0.77896701  0.86833035  1.03091241  0.28635223\n",
      "  0.76158125  1.1189193   0.11661389  1.18809966  0.81436675  0.24330064\n",
      "  0.76940652  0.82461336  0.74966819  1.10307951  0.76838272  0.69771513\n",
      "  0.85905949  1.00974254  1.17387529  0.80001     0.99297996  0.96166813\n",
      "  0.52154463  1.10309365  0.2973281   0.85510046  0.599992    1.11804132\n",
      "  0.50635798  0.76001     0.95415429  0.32248535  0.40793137  0.56604735\n",
      "  0.78229432  0.73757115  0.53666526  0.86580437  0.71693291  0.99458273\n",
      "  0.44720465  0.67911943  1.11212122  0.8202368 ]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "[ 0.98731839  1.23224186  0.91585501  1.15602163  1.10345639  1.22441039\n",
      "  0.41232026  1.34358431  1.3862248   0.651143    0.62031895  0.58821459\n",
      "  0.99640132  0.98182666  1.21606727  0.36877527  0.92196356  0.79648754\n",
      "  0.85907904  0.88813603  0.83569971  1.02000882  0.5280072   1.05602424\n",
      "  0.32556965  0.33527064  0.76156864  0.52497314  0.77819406  1.00578029\n",
      "  1.29322079  0.6597066   0.8246187   0.68117604  1.05395332  0.96041137\n",
      "  0.65392048  0.92129887  0.78817054  0.94762989  1.200006    0.72471567\n",
      "  0.73376045  0.91412144  0.30595098  1.12801507  0.64498558  0.66483442\n",
      "  1.15964667  0.91783332  0.44045477  0.94762989  0.2953012   0.51263671\n",
      "  0.92196421  1.01980194  0.77898113  0.86832183  1.03091881  0.2863655\n",
      "  0.7615865   1.11893288  0.11661046  1.18811363  0.81438001  0.24331215\n",
      "  0.76942004  0.82462743  0.74967646  1.10307951  0.76836866  0.69771943\n",
      "  0.85907136  1.00975106  1.17388943  0.8         0.99298419  0.96167479\n",
      "  0.52153082  1.10307951  0.29732877  0.85511216  0.600006    1.11802719\n",
      "  0.50636943  0.76        0.95414045  0.32248163  0.40792352  0.56603357\n",
      "  0.78230352  0.73755705  0.53666079  0.86579559  0.71694658  0.99457569\n",
      "  0.44720912  0.67912679  1.11212301  0.82025094]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "[ 0.9873196   1.23223374  0.91586025  1.15602768  1.10344914  1.22441823\n",
      "  0.41231056  1.34357731  1.38621788  0.65115282  0.6203225   0.58821765\n",
      "  0.9963935   0.98183502  1.21605921  0.36878178  0.92195445  0.79649231\n",
      "  0.85906926  0.88814413  0.8357033   1.02        0.52801515  1.0560303\n",
      "  0.32557641  0.33526109  0.76157731  0.52497619  0.77820306  1.00578328\n",
      "  1.29321305  0.6596969   0.82462113  0.68117545  1.05394497  0.96041658\n",
      "  0.65391131  0.92130342  0.78816242  0.94762862  1.2         0.72470684\n",
      "  0.73375745  0.91411159  0.30594117  1.12800709  0.64498062  0.66483081\n",
      "  1.15965512  0.91782351  0.44045431  0.94762862  0.29529646  0.51264022\n",
      "  0.92195445  1.0198039   0.77897368  0.86833173  1.03092192  0.28635642\n",
      "  0.76157731  1.11892806  0.11661904  1.18810774  0.81437092  0.2433105\n",
      "  0.76941536  0.82462113  0.74966659  1.10308658  0.76837491  0.69771054\n",
      "  0.85906926  1.00975244  1.17388245  0.8         0.99297533  0.96166522\n",
      "  0.52153619  1.10308658  0.29732137  0.85510233  0.6         1.11803399\n",
      "  0.50635956  0.76        0.95414884  0.32249031  0.40792156  0.56603887\n",
      "  0.78230429  0.73756356  0.53665631  0.86579443  0.71693793  0.99458534\n",
      "  0.4472136   0.67911707  1.1121151   0.82024387]\n",
      "Autograd ArrayNode with value [ 0.98731686  1.23230486  0.91580359  1.15596386  1.10352325  1.22433917\n",
      "  0.41239956  1.34363678  1.38628922  0.65105891  0.62029736  0.58819723\n",
      "  0.99646159  0.98175178  1.21612973  0.3687273   0.92203642  0.79645518\n",
      "  0.85916293  0.88807311  0.83566143  1.02008698  0.52793516  1.05596644\n",
      "  0.32550652  0.33534813  0.76149156  0.52493926  0.7781224   1.00574693\n",
      "  1.29328014  0.6597859   0.82460682  0.68118969  1.05401858  0.96036023\n",
      "  0.65400096  0.92125284  0.78823359  0.94763185  1.20006334  0.72479388\n",
      "  0.73379395  0.91420559  0.30603498  1.12808729  0.64501964  0.66485657\n",
      "  1.15957108  0.91791732  0.44046731  0.94764918  0.29534869  0.51261543\n",
      "  0.92204802  1.01979405  0.77904944  0.86823992  1.03090107  0.28644536\n",
      "  0.7616602   1.11898104  0.11654301  1.18817013  0.81445991  0.24333457\n",
      "  0.76946703  0.82468713  0.7497579   1.10302635  0.76830942  0.69779\n",
      "  0.85909749  1.00974808  1.1739543   0.79999127  0.99305451  0.96175253\n",
      "  0.52147841  1.10301399  0.297385    0.85519623  0.60006334  1.11796374\n",
      "  0.50645367  0.75999127  0.95406533  0.3224131   0.40793143  0.56598169\n",
      "  0.7823058   0.73749581  0.53669051  0.86579661  0.71702354  0.99449697\n",
      "  0.44717941  0.67920629  1.11218408  0.82031645] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98731418  1.2323748   0.91574788  1.1559011   1.10359613  1.22426142\n",
      "  0.41248708  1.34369527  1.38635939  0.65096654  0.62027266  0.58817717\n",
      "  0.99652855  0.98166991  1.21619908  0.36867374  0.92211703  0.79641869\n",
      "  0.85925504  0.88800327  0.83562027  1.02017252  0.52785648  1.05590363\n",
      "  0.32543779  0.33543373  0.76140723  0.52490294  0.77804307  1.00571119\n",
      "  1.29334612  0.65987342  0.82459278  0.68120372  1.05409098  0.96030481\n",
      "  0.65408913  0.92120309  0.78830358  0.94763504  1.20012564  0.72487948\n",
      "  0.73382986  0.91429803  0.30612723  1.12816617  0.64505802  0.66488192\n",
      "  1.15948844  0.91800958  0.44048012  0.94766942  0.29540008  0.51259107\n",
      "  0.92214005  1.01978438  0.77912396  0.86814964  1.03088058  0.28653283\n",
      "  0.76174171  1.11903315  0.11646827  1.1882315   0.81454743  0.24335829\n",
      "  0.76951785  0.82475205  0.7498477   1.10296712  0.76824502  0.69786813\n",
      "  0.85912526  1.0097438   1.17402498  0.79998269  0.99313239  0.96183839\n",
      "  0.52142158  1.10294261  0.29744759  0.85528857  0.60012565  1.11789466\n",
      "  0.50654624  0.75998269  0.95398321  0.32233719  0.40794114  0.56592546\n",
      "  0.7823073   0.73742918  0.53672415  0.86579876  0.71710773  0.99441007\n",
      "  0.44714582  0.67929403  1.11225192  0.82038785] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98731156  1.23244361  0.91569305  1.15583935  1.10366786  1.22418492\n",
      "  0.4125732   1.34375281  1.38642844  0.65087566  0.62024838  0.58815745\n",
      "  0.99659443  0.98158936  1.21626731  0.36862106  0.92219635  0.79638279\n",
      "  0.85934568  0.88793457  0.83557977  1.0202567   0.52777908  1.05584184\n",
      "  0.32537017  0.33551796  0.76132426  0.52486722  0.77796503  1.00567602\n",
      "  1.29341103  0.65995953  0.82457897  0.68121753  1.05416221  0.96025029\n",
      "  0.65417588  0.92115415  0.78837244  0.94763817  1.20018695  0.72496371\n",
      "  0.7338652   0.91438899  0.30621801  1.12824379  0.64509578  0.66490686\n",
      "  1.15940712  0.91810035  0.44049275  0.94768934  0.29545066  0.51256713\n",
      "  0.9222306   1.01977488  0.77919728  0.8680608   1.03086044  0.28661889\n",
      "  0.76182191  1.11908443  0.11639476  1.18829189  0.81463354  0.24338166\n",
      "  0.76956787  0.82481594  0.74993605  1.10290886  0.76818165  0.69794502\n",
      "  0.8591526   1.0097396   1.17409452  0.79997426  0.99320902  0.96192287\n",
      "  0.52136568  1.10287237  0.29750918  0.85537942  0.60018696  1.11782668\n",
      "  0.50663731  0.75997426  0.95390241  0.32226251  0.40795072  0.56587015\n",
      "  0.7823088   0.73736363  0.53675726  0.86580087  0.71719058  0.99432457\n",
      "  0.44711279  0.67938036  1.11231866  0.8204581 ] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98720238  1.23265095  0.91566541  1.15579113  1.10374852  1.22408705\n",
      "  0.41278165  1.34394978  1.3865      0.65070163  0.62009913  0.58801615\n",
      "  0.9967995   0.9814755   1.21647423  0.36842975  0.92240805  0.7962147\n",
      "  0.85951657  0.88772731  0.83559111  1.02038661  0.52767779  1.05579348\n",
      "  0.32530343  0.3357282   0.76119991  0.52489074  0.77775344  1.00570091\n",
      "  1.29361528  0.66016799  0.82444835  0.68114275  1.05437113  0.9602235\n",
      "  0.65431891  0.92114301  0.78857982  0.94774842  1.20023385  0.72509391\n",
      "  0.73384084  0.91456417  0.30639062  1.12834595  0.64526675  0.66505728\n",
      "  1.15929001  0.91827294  0.44041539  0.9476282   0.29546647  0.51241847\n",
      "  0.92240055  1.01965232  0.77928358  0.86785744  1.03071837  0.28675827\n",
      "  0.76203359  1.1191021   0.11618462  1.18833601  0.81477313  0.24332852\n",
      "  0.76958204  0.82487084  0.75014066  1.10271112  0.76812846  0.69815639\n",
      "  0.85910871  1.00962731  1.17416776  0.80006074  0.99342033  0.96213292\n",
      "  0.52133493  1.10279685  0.29771036  0.85555313  0.60023392  1.11775872\n",
      "  0.50681453  0.76006075  0.95378748  0.32205184  0.40807349  0.56584109\n",
      "  0.78220792  0.73730352  0.53692105  0.86590909  0.71731439  0.99411542\n",
      "  0.44694918  0.67958855  1.11252443  0.82053375] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98709612  1.23285324  0.91563819  1.15574381  1.10382756  1.2239913\n",
      "  0.41298514  1.3441419   1.38657015  0.65053164  0.61995373  0.58787851\n",
      "  0.99699957  0.98136416  1.2166761   0.36824319  0.92261466  0.79605086\n",
      "  0.85968355  0.8875251   0.83560194  1.02051365  0.52757873  1.05574604\n",
      "  0.32523814  0.33593342  0.76107836  0.52491348  0.77754694  1.00572495\n",
      "  1.29381453  0.66037148  0.82432114  0.68107009  1.05457499  0.96019711\n",
      "  0.65445875  0.92113189  0.78878215  0.94785579  1.20027995  0.72522124\n",
      "  0.73381741  0.91473531  0.3065593   1.12844595  0.64543345  0.6652039\n",
      "  1.15917549  0.91844156  0.44034025  0.94756885  0.29548233  0.51227365\n",
      "  0.92256659  1.01953298  0.77936812  0.86765889  1.03057997  0.2868946\n",
      "  0.76224018  1.11911968  0.11597958  1.18837939  0.81490962  0.24327712\n",
      "  0.76959622  0.82492476  0.75034043  1.10251825  0.76807631  0.69836267\n",
      "  0.85906621  1.009518    1.17423954  0.80014492  0.99362653  0.96233796\n",
      "  0.52130471  1.1027229   0.29790662  0.85572285  0.6002801   1.11769214\n",
      "  0.50698766  0.76014493  0.9536751   0.32184628  0.40819314  0.56581252\n",
      "  0.78210978  0.73724463  0.53708074  0.86601448  0.7174355   0.99391127\n",
      "  0.44678973  0.67979178  1.11272518  0.82060789] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98710742  1.23303187  0.91547161  1.15555915  1.10403782  1.22376925\n",
      "  0.41321772  1.34428711  1.38677364  0.65027806  0.61990439  0.58784208\n",
      "  0.99716946  0.98113228  1.216853    0.36811244  0.92282538  0.79596845\n",
      "  0.85993693  0.88734685  0.8354733   1.02075411  0.52735452  1.05556128\n",
      "  0.32503858  0.33615976  0.76084075  0.52479774  0.77734023  1.00561059\n",
      "  1.29398152  0.66060405  0.82430127  0.68112682  1.05476091  0.96003131\n",
      "  0.65470496  0.92098079  0.78896096  0.94784619  1.20046361  0.72546184\n",
      "  0.73393255  0.91498894  0.30681282  1.12867082  0.64552148  0.66525546\n",
      "  1.15894177  0.91869508  0.44039383  0.94764222  0.29563827  0.5122253\n",
      "  0.92281988  1.01952511  0.77958242  0.8674169   1.03054224  0.28713937\n",
      "  0.76245368  1.11927718  0.115787    1.18856068  0.81515443  0.24336029\n",
      "  0.76975043  0.82511511  0.75058068  1.10237101  0.76788753  0.69856584\n",
      "  0.85915974  1.00952492  1.1744443   0.80010334  0.9938289   0.96256512\n",
      "  0.52113538  1.10251651  0.29806389  0.85597642  0.60046387  1.1174915\n",
      "  0.5072413   0.76010337  0.95344261  0.32164996  0.40820166  0.56564471\n",
      "  0.78213254  0.73705022  0.53715551  0.86600206  0.7176729   0.99368074\n",
      "  0.44671561  0.68002506  1.11289763  0.82081448] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.9871185   1.2332061   0.91530921  1.15537911  1.10424287  1.22355274\n",
      "  0.41344454  1.34442875  1.38697209  0.65003077  0.61985636  0.58780664\n",
      "  0.99733516  0.98090618  1.21702554  0.36798506  0.9230309   0.79588816\n",
      "  0.86018402  0.88717306  0.83534792  1.0209886   0.52713591  1.05538114\n",
      "  0.32484406  0.33638053  0.76060905  0.52468498  0.77713867  1.00549912\n",
      "  1.29414439  0.66083085  0.82428195  0.68118222  1.05494224  0.95986967\n",
      "  0.65494506  0.92083349  0.78913538  0.94783689  1.20064273  0.72569647\n",
      "  0.7340449   0.91523627  0.30706004  1.12889012  0.64560742  0.66530584\n",
      "  1.15871386  0.9189423   0.44044621  0.94771382  0.29579046  0.51217827\n",
      "  0.92306688  1.01951749  0.77979141  0.86718093  1.03050551  0.28737808\n",
      "  0.76266191  1.11943079  0.11559943  1.18873749  0.81539318  0.24344161\n",
      "  0.76990086  0.82530076  0.75081497  1.10222747  0.76770347  0.69876401\n",
      "  0.859251    1.00953173  1.17464399  0.80006288  0.99402627  0.96278666\n",
      "  0.52097033  1.10231528  0.29821738  0.8562237   0.60064311  1.11729587\n",
      "  0.50748863  0.76006292  0.95321591  0.3214586   0.40821012  0.56548114\n",
      "  0.78215481  0.73686068  0.53722852  0.86599002  0.71790442  0.99345595\n",
      "  0.44664345  0.68025256  1.11306583  0.82101595] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98712936  1.23337617  0.91515077  1.15520342  1.10444299  1.22334145\n",
      "  0.41366593  1.34456702  1.38716577  0.64978943  0.61980957  0.58777216\n",
      "  0.99749692  0.98068552  1.21719395  0.36786085  0.92323149  0.79580985\n",
      "  0.86042516  0.88700349  0.83522561  1.02121744  0.52692259  1.05520536\n",
      "  0.32465429  0.33659601  0.76038294  0.52457502  0.77694199  1.00539039\n",
      "  1.29430337  0.66105222  0.82426317  0.68123636  1.05511923  0.95971196\n",
      "  0.65517939  0.92068978  0.78930564  0.94782789  1.20081755  0.72592546\n",
      "  0.73415461  0.91547764  0.30730132  1.12910414  0.64569138  0.6653551\n",
      "  1.15849144  0.91918356  0.44049745  0.94778374  0.2959391   0.51213247\n",
      "  0.92330793  1.01951011  0.77999538  0.86695064  1.03046971  0.28761105\n",
      "  0.76286515  1.11958073  0.11541658  1.18891007  0.81562617  0.24352118\n",
      "  0.7700477   0.82548197  0.75104363  1.1020874   0.76752388  0.69895744\n",
      "  0.85934012  1.00953843  1.17483889  0.80002347  0.99421892  0.96300288\n",
      "  0.52080932  1.10211891  0.29836731  0.85646503  0.60081808  1.11710498\n",
      "  0.50773001  0.76002353  0.95299468  0.3212719   0.40821853  0.56532156\n",
      "  0.78217661  0.73667573  0.53729989  0.86597835  0.71813037  0.99323658\n",
      "  0.44657315  0.68047461  1.11323001  0.8212126 ] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98714002  1.23354229  0.91499606  1.15503187  1.10463846  1.22313511\n",
      "  0.41388217  1.3447021   1.38735495  0.64955372  0.61976396  0.58773856\n",
      "  0.99765493  0.98047004  1.21735846  0.36773965  0.92342742  0.79573343\n",
      "  0.86066067  0.8868379   0.83510622  1.02144095  0.52671427  1.05503372\n",
      "  0.32446902  0.33680651  0.76016212  0.52446772  0.77674992  1.00528425\n",
      "  1.29445867  0.66126843  0.82424488  0.68128931  1.05529213  0.95955797\n",
      "  0.65540824  0.92054947  0.78947196  0.94781917  1.20098832  0.72614911\n",
      "  0.7342618   0.91571338  0.30753695  1.12931318  0.64577346  0.66540329\n",
      "  1.15827423  0.9194192   0.44054761  0.94785209  0.29608439  0.51208784\n",
      "  0.92354335  1.01950295  0.78019462  0.86672573  1.03043479  0.2878386\n",
      "  0.76306367  1.1197272   0.11523821  1.18907863  0.81585374  0.24359909\n",
      "  0.77019116  0.82565898  0.75126696  1.10195064  0.76734853  0.69914639\n",
      "  0.85942721  1.00954501  1.17502925  0.79998505  0.99440709  0.96321407\n",
      "  0.52065213  1.10192715  0.29851386  0.85670072  0.60098901  1.11691856\n",
      "  0.50796576  0.75998514  0.95277863  0.32108964  0.40822688  0.56516578\n",
      "  0.78219797  0.73649514  0.53736969  0.86596702  0.71835106  0.99302233\n",
      "  0.44650459  0.68069148  1.11339039  0.82140467] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98715049  1.23370467  0.91484489  1.15486423  1.10482951  1.22293345\n",
      "  0.41409354  1.34483415  1.38753984  0.64932336  0.61971946  0.58770581\n",
      "  0.9978094   0.98025944  1.21751927  0.3676213   0.92361894  0.7956588\n",
      "  0.86089085  0.88667609  0.83498958  1.0216594   0.5265107   1.05486599\n",
      "  0.32428802  0.33701227  0.75994632  0.52436294  0.77656222  1.00518056\n",
      "  1.29461048  0.66147976  0.82422707  0.68134113  1.05546113  0.95940751\n",
      "  0.65563192  0.92041238  0.78963456  0.9478107   1.20115523  0.7263677\n",
      "  0.73436662  0.91594378  0.30776726  1.12951749  0.64585375  0.66545048\n",
      "  1.15806194  0.91964949  0.44059675  0.94791893  0.29622649  0.51204432\n",
      "  0.92377344  1.019496    0.78038935  0.86650592  1.03040071  0.288061\n",
      "  0.76325771  1.11987037  0.11506408  1.18924339  0.81607614  0.24367543\n",
      "  0.77033141  0.825832    0.75148525  1.10181701  0.76717718  0.69933109\n",
      "  0.85951237  1.0095515   1.17521531  0.79994758  0.99459102  0.96342049\n",
      "  0.52049856  1.10173975  0.2986572   0.85693107  0.6011561   1.11673639\n",
      "  0.50819616  0.75994769  0.95256748  0.32091156  0.40823519  0.56501358\n",
      "  0.7822189   0.73631867  0.53743801  0.86595601  0.71856675  0.99281295\n",
      "  0.44643769  0.68090346  1.11354717  0.82159241] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98716077  1.2338635   0.9146971   1.1547003   1.10501637  1.22273625\n",
      "  0.41430028  1.34496332  1.38772068  0.64909807  0.61967601  0.58767386\n",
      "  0.99796051  0.98005349  1.21767656  0.36750565  0.92380625  0.79558586\n",
      "  0.86111595  0.88651786  0.83487557  1.02187304  0.52631164  1.05470198\n",
      "  0.32411107  0.33721354  0.75973528  0.52426055  0.77637867  1.0050792\n",
      "  1.29475898  0.66168646  0.8242097   0.68139187  1.05562645  0.95926039\n",
      "  0.65585068  0.92027836  0.78979361  0.94780249  1.20131848  0.72658148\n",
      "  0.73446918  0.91616911  0.30799249  1.1297173   0.64593236  0.6654967\n",
      "  1.15785434  0.91987472  0.4406449   0.94798434  0.29636556  0.51200185\n",
      "  0.92399847  1.01948924  0.78057982  0.86629095  1.03036742  0.28827851\n",
      "  0.76344751  1.12001041  0.11489396  1.18940454  0.81629366  0.24375027\n",
      "  0.77046861  0.82600124  0.75169873  1.10168634  0.76700964  0.69951175\n",
      "  0.85959571  1.00955788  1.17539729  0.799911    0.99477093  0.96362238\n",
      "  0.52034844  1.1015565   0.2987975   0.85715636  0.60131955  1.11655825\n",
      "  0.50842149  0.75991114  0.95236099  0.32073747  0.40824344  0.56486479\n",
      "  0.78223943  0.73614613  0.53750492  0.86594532  0.7187777   0.99260817\n",
      "  0.44637236  0.68111079  1.11370052  0.82177603] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98717088  1.23401897  0.91455249  1.15453991  1.10519923  1.22254328\n",
      "  0.41450261  1.34508976  1.38789765  0.6488776   0.61963355  0.58764266\n",
      "  0.99810841  0.97985196  1.21783052  0.36739257  0.92398959  0.79551453\n",
      "  0.86133625  0.88636304  0.83476404  1.02208211  0.52611686  1.05454151\n",
      "  0.32393797  0.33741053  0.75952876  0.52416043  0.77619907  1.00498006\n",
      "  1.29490432  0.66188874  0.82419276  0.68144159  1.05578825  0.95911646\n",
      "  0.65606475  0.92014724  0.7899493   0.94779451  1.20147826  0.7267907\n",
      "  0.7345696   0.91638961  0.3082129   1.12991285  0.64600936  0.66554202\n",
      "  1.15765119  0.92009513  0.44069213  0.94804839  0.29650176  0.51196037\n",
      "  0.92421868  1.01948267  0.78076622  0.86608058  1.03033488  0.28849138\n",
      "  0.76363327  1.12014748  0.11472767  1.18956226  0.81650652  0.24382368\n",
      "  0.7706029   0.82616687  0.75190766  1.10155848  0.76684571  0.69968858\n",
      "  0.8596773   1.00956417  1.17557538  0.79987527  0.99494701  0.96381996\n",
      "  0.52020158  1.10137718  0.2989349   0.85737682  0.60147954  1.11638394\n",
      "  0.508642    0.75987544  0.95215893  0.32056716  0.40825165  0.56471923\n",
      "  0.78225958  0.7359773   0.53757049  0.86593491  0.71898414  0.99240779\n",
      "  0.44630852  0.68131369  1.11385063  0.82195575] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98722277  1.23423865  0.91429746  1.15426243  1.10550763  1.22222168\n",
      "  0.4148074   1.34525974  1.38819811  0.64852927  0.61960202  0.58762919\n",
      "  0.99831503  0.97951966  1.21804759  0.36724532  0.92425872  0.79543616\n",
      "  0.86168518  0.88614459  0.83455731  1.02242316  0.52579296  1.05426392\n",
      "  0.3236429   0.33770505  0.75919058  0.52397072  0.77593679  1.00479175\n",
      "  1.29510653  0.66219341  0.82420197  0.68155508  1.05601901  0.95886238\n",
      "  0.65641089  0.9199117   0.79016941  0.94774615  1.20175494  0.7271319\n",
      "  0.73475998  0.91673763  0.30856151  1.13023776  0.64609726  0.66557848\n",
      "  1.15731695  0.92044376  0.44080186  0.94818382  0.29674491  0.51193042\n",
      "  0.92456776  1.01950829  0.78107931  0.86575969  1.03031919  0.28883638\n",
      "  0.76390684  1.12039176  0.11448951  1.18983604  0.81685151  0.24397361\n",
      "  0.77084319  0.82645176  0.7522256   1.10138623  0.7665633   0.69994597\n",
      "  0.85983939  1.00961008  1.17587735  0.79978363  0.99520305  0.96411555\n",
      "  0.51994336  1.1010736   0.29912368  0.85772521  0.60175655  1.11608715\n",
      "  0.5089894   0.75978385  0.95182599  0.3203216   0.40822895  0.56446286\n",
      "  0.78232722  0.73568808  0.53763975  0.86588276  0.71932226  0.99210688\n",
      "  0.44624246  0.68161956  1.11406104  0.82225992] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98727319  1.23445269  0.91404944  1.15399252  1.10580771  1.22190877\n",
      "  0.4151042   1.34542543  1.38849046  0.64819023  0.6195713   0.58761608\n",
      "  0.99851637  0.97919632  1.21825909  0.36710209  0.92452085  0.79535982\n",
      "  0.86202481  0.88593189  0.83435637  1.02275506  0.52547782  1.05399392\n",
      "  0.32335593  0.33799192  0.7588615   0.52378642  0.77568144  1.00460873\n",
      "  1.29530356  0.66249007  0.82421086  0.68166551  1.05624382  0.9586153\n",
      "  0.65674775  0.91968269  0.79038388  0.94769941  1.20202413  0.72746395\n",
      "  0.7349452   0.91707637  0.30890083  1.13055393  0.64618318  0.66561434\n",
      "  1.1569917   0.92078309  0.44090871  0.94831555  0.29698161  0.5119013\n",
      "  0.92490752  1.01953314  0.78138398  0.86544732  1.03030382  0.28917214\n",
      "  0.76417329  1.12062941  0.11425812  1.19010242  0.81718725  0.24411974\n",
      "  0.77107698  0.82672896  0.75253515  1.10121849  0.76628861  0.70019671\n",
      "  0.85999707  1.00965467  1.17617118  0.79969477  0.99545244  0.96440339\n",
      "  0.51969227  1.10077826  0.29930787  0.8580643   0.6020261   1.11579844\n",
      "  0.50932755  0.75969505  0.95150202  0.32008264  0.40820735  0.56421358\n",
      "  0.782393    0.73540675  0.53770759  0.86583234  0.71965129  0.99181393\n",
      "  0.4461782   0.6819174   1.11426606  0.8225559 ] and 1 progenitors(s)\n",
      "Autograd ArrayNode with value [ 0.98732222  1.2346614   0.91380803  1.15372975  1.10609997  1.22160404\n",
      "  0.4153935   1.34558707  1.38877517  0.64785995  0.61954136  0.58760329\n",
      "  0.99871274  0.97888141  1.21846532  0.36696262  0.92477637  0.7952854\n",
      "  0.86235567  0.88572461  0.83416086  1.02307834  0.52517094  1.05373105\n",
      "  0.32307659  0.33827157  0.75854099  0.5236072   0.77543263  1.00443068\n",
      "  1.29549571  0.66277921  0.82421947  0.68177303  1.05646302  0.95837479\n",
      "  0.65707587  0.91945981  0.79059305  0.94765419  1.20228628  0.72778737\n",
      "  0.73512558  0.91740637  0.30923139  1.13086186  0.64626723  0.66564964\n",
      "  1.15667493  0.92111366  0.44101283  0.94844379  0.29721225  0.51187295\n",
      "  0.92523851  1.01955726  0.78168071  0.86514297  1.03028876  0.28949919\n",
      "  0.76443304  1.12086083  0.11403308  1.19036183  0.81751427  0.24426229\n",
      "  0.77130466  0.82699892  0.75283681  1.10105498  0.76602119  0.70044117\n",
      "  0.8601506   1.00969801  1.17645734  0.79960853  0.99569557  0.96468392\n",
      "  0.51944791  1.10049068  0.29948772  0.85839465  0.60228863  1.11551733\n",
      "  0.50965697  0.75960888  0.9511865   0.31984989  0.40818678  0.56397097\n",
      "  0.78245701  0.73513286  0.53777406  0.86578354  0.71997178  0.99152848\n",
      "  0.44611566  0.68220767  1.114466    0.82284416] and 1 progenitors(s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4a68c77742da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplotScatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainBoundaryHunter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[1;31m# plt.scatter(weights[1], weights[2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8a8153abcc8e>\u001b[0m in \u001b[0;36mtrainBoundaryHunter\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initial Loss: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danie\\Anaconda3\\lib\\site-packages\\autograd\\errors.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0madd_extra_error_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danie\\Anaconda3\\lib\\site-packages\\autograd\\convenience_wrappers.py\u001b[0m in \u001b[0;36mgradfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mvjp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar_fun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_to_same_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danie\\Anaconda3\\lib\\site-packages\\autograd\\core.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mstart_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_node\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mstart_node\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mend_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogenitors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Output seems independent of input.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danie\\Anaconda3\\lib\\site-packages\\autograd\\core.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(fun, args, kwargs, argnum)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mactive_progenitors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mend_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mactive_progenitors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_node\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danie\\Anaconda3\\lib\\site-packages\\autograd\\convenience_wrappers.py\u001b[0m in \u001b[0;36mscalar_fun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mscalar_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mas_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mattach_name_and_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Gradient'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6851098a8883>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnonLocalPoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnonLocalTargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnonLocalPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnonLocalR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6851098a8883>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mnonLocalPoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnonLocalTargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mnonLocalPredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnonLocalR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnotLocal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\danie\\Anaconda3\\lib\\site-packages\\autograd\\core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0margvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0margnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_vjps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mparents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mprogenitors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogenitors\u001b[0m \u001b[1;33m&\u001b[0m \u001b[0mactive_progenitors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQBARkZgCgoiIAAoIIiIS+3/e9dGMn4LyOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17fd515e128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "points, targets = generateChevronData()\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "\n",
    "# Plot points on graph\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    if targets[i] == 0:\n",
    "        c1.append(points[i])\n",
    "    else:\n",
    "        c2.append(points[i])\n",
    "\n",
    "print(\"Type 0: \", len(c1))\n",
    "print(\"Type 1: \", len(c2))\n",
    "        \n",
    "plotScatter(c1)\n",
    "plotScatter(c2)\n",
    "\n",
    "weights = trainBoundaryHunter()\n",
    "\n",
    "# plt.scatter(weights[1], weights[2])\n",
    "plt.scatter(weights[2], weights[3])\n",
    "\n",
    "n = np.array([weights[0] * weights[2] + weights[1] * weights[3], \n",
    "              -weights[0], \n",
    "              -weights[1]])\n",
    "\n",
    "byas = -1 * n[0]/n[2]\n",
    "Xcoef = -1 * n[1]/n[2]\n",
    "\n",
    "x = np.linspace(-1.5, 1.5, 500)\n",
    "y = np.linspace(-1.5, 1.5, 500)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "F = ((X - weights[2]))**2 + ((Y - weights[3]))**2 - weights[4]**2\n",
    "plt.contour(X,Y,F,[0])\n",
    "\n",
    "print()\n",
    "print(n)\n",
    "print(\"\\nLine\")\n",
    "print(\"B: \" + str(byas))\n",
    "print(\"XCoef: \" + str(Xcoef))\n",
    "\n",
    "plt.plot([-1.0, 1.0], [-1*Xcoef + byas, Xcoef + byas], 'k-')\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
