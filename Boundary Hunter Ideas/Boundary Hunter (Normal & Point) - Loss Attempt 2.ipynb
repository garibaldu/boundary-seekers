{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from autograd import grad\n",
    "\n",
    "def generateChevronData():\n",
    "    xBounds = [-50, 50]\n",
    "    yBounds = [-50, 50]\n",
    "    totalPoints = 100\n",
    "    \n",
    "    points = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, totalPoints):\n",
    "        x = random.randint(xBounds[0], xBounds[1])\n",
    "        y = random.randint(yBounds[0], yBounds[1])\n",
    "        \n",
    "        if x >= y and x <= -y:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(1)\n",
    "        \n",
    "    return np.array(points), np.array(targets)\n",
    "    \n",
    "def plotScatter(points):\n",
    "    xs = [x[0] for x in points]\n",
    "    ys = [y[1] for y in points]\n",
    "    \n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    return 1.0/(1.0 + np.exp(-phi))\n",
    "\n",
    "def loss(weights):\n",
    "    predictions = logisticPrediction(weights, points)\n",
    "#     crossEntropy = (targets*np.log(predictions) + (1-targets)*np.log(1-predictions))\n",
    "    r = responsibility(weights, points)\n",
    "    notLocal = list(map(lambda x: not (r[x] < 0.5 ),range(0, len(points))))\n",
    "    \n",
    "    crossEntropyRScaled = r * (crossEntropy(targets, predictions))\n",
    "    opositeCrossEntropyRScaled = r * (crossEntropy(1-targets, predictions))\n",
    "    \n",
    "    local = np.array([crossEntropyRScaled[i] for i in range(0, len(points)) if notLocal[i] == False])\n",
    "    outside = np.array([opositeCrossEntropyRScaled[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "    \n",
    "    localLoss = 0\n",
    "    if not len(local) == 0:\n",
    "#         print(\"LOCAL EMPTY\")\n",
    "        localLoss = (1/len(local)) * np.sum(local)\n",
    "    \n",
    "    outsideLoss = 0\n",
    "    if not len(outside) == 0:\n",
    "#         print(\"OUTSIDE EMPTY\")\n",
    "        outsideLoss = (1/len(outside)) * np.sum(outside)\n",
    "    \n",
    "    return -(localLoss + outsideLoss)\n",
    "    \n",
    "#     nonLocalPoints = np.array([points[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "#     nonLocalTargets = np.array([targets[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "#     nonLocalPredictions = np.array([predictions[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "#     nonLocalR = np.array([r[i] for i in range(0, len(points)) if notLocal[i] for i in range(0, len(points)) if notLocal[i] == True])\n",
    "\n",
    "#     return -(1/len(localPoints)) * (np.sum(crossEntropy(localTargets, localPredictions))) -(1/len(nonLocalPoints)) * (np.sum(nonLocalR * invCrossEntropy(nonLocalTargets, nonLocalPredictions)))\n",
    "    \n",
    "def crossEntropy(t, p):\n",
    "    return t * np.log(p) + (1-t) * np.log(1-p)\n",
    "\n",
    "def logisticPrediction(weights, p):\n",
    "    return np.array(list(map(lambda x: predict(weights, x), p))) \n",
    "    \n",
    "def predict(weights, inputs):\n",
    "    n = np.array([weights[0], weights[1]])\n",
    "    i = np.array([weights[2] - inputs[0], weights[3] - inputs[1]])\n",
    "    return sigmoid(np.dot(n, i))\n",
    "\n",
    "def responsibility(weights, points):\n",
    "    r = np.absolute(weights[4])\n",
    "    a = np.array([weights[2], weights[3]])\n",
    "    \n",
    "    dif = np.array(list(map(lambda x: x - a, points)))\n",
    "    s = np.array(list(map(lambda x: np.sum(np.power(x, 2)), dif)))\n",
    "    d = np.sqrt(s)\n",
    "\n",
    "    t = 1 - f(d, r)\n",
    "    return t\n",
    "\n",
    "def f(d, r):\n",
    "    return 1/(1 + np.power(np.e, -(d-r)))\n",
    "#     return 1/(1 + np.power(np.e, 10*(d-r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainBoundaryHunter():\n",
    "    weights = np.array([0.0, 0.0, 0.0, 0.0, 0.3])\n",
    "    gradient = grad(loss)\n",
    "    print(\"Initial Loss: \", loss(weights))\n",
    "    for i in range(0, 10000):\n",
    "        g = gradient(weights)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss [i = \" + str(i) + \"]: \" + str(loss(weights)))\n",
    "            print(weights)\n",
    "            checkGrad(0.00001, 0.0001, weights, g)\n",
    "        \n",
    "#         weights = computeStep(weights)\n",
    "        weights -= 0.001 * g\n",
    "        if weights[4] < 0:\n",
    "            weights[4] = 0\n",
    "            \n",
    "    print(\"Trained Loss: \", loss(weights))    \n",
    "    print(\"Weights: \", weights)\n",
    "    return weights\n",
    "\n",
    "def checkGrad(pterb, threshold, weights, g):\n",
    "    grad = np.zeros(len(weights))\n",
    "    for i in range(0, len(weights)):\n",
    "        p = np.zeros(len(weights))\n",
    "        p[i] = pterb\n",
    "        \n",
    "        lossBefore = loss(weights)\n",
    "        lossAfter = loss(weights + p)\n",
    "        \n",
    "        grad[i] = (lossAfter - lossBefore)/pterb\n",
    "        \n",
    "\n",
    "    return grad\n",
    "\n",
    "    dif = np.absolute(computedGrad - grad)\n",
    "    for d in dif:\n",
    "        if d > threshold:\n",
    "            print(\"ERROR\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0:  35\n",
      "Type 1:  65\n",
      "Initial Loss:  0.612553827648\n",
      "Loss [i = 0]: 0.612553827648\n",
      "[ 0.   0.   0.   0.   0.3]\n",
      "Loss [i = 1000]: 0.224555983405\n",
      "[ 0.00527843 -0.05153148 -0.05207263 -0.01960584  0.07782886]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/pkg/lib/python3.6/site-packages/autograd/core.py:133: RuntimeWarning: invalid value encountered in true_divide\n",
      "  result = self.fun(*argvals, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [i = 2000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Loss [i = 3000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Loss [i = 4000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Loss [i = 5000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Loss [i = 6000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Loss [i = 7000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Loss [i = 8000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Loss [i = 9000]: nan\n",
      "[ nan  nan  nan  nan  nan]\n",
      "Trained Loss:  nan\n",
      "Weights:  [ nan  nan  nan  nan  nan]\n",
      "\n",
      "[ nan  nan  nan]\n",
      "\n",
      "Line\n",
      "B: nan\n",
      "XCoef: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/pkg/lib/python3.6/site-packages/matplotlib/contour.py:1534: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmax = float(z.max())\n",
      "/usr/pkg/lib/python3.6/site-packages/matplotlib/contour.py:1535: UserWarning: Warning: converting a masked element to nan.\n",
      "  self.zmin = float(z.min())\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAREAAAEACAYAAACUHkKwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnEep+EAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a770d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "points, targets = generateChevronData()\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "\n",
    "# Plot points on graph\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    if targets[i] == 0:\n",
    "        c1.append(points[i])\n",
    "    else:\n",
    "        c2.append(points[i])\n",
    "\n",
    "print(\"Type 0: \", len(c1))\n",
    "print(\"Type 1: \", len(c2))\n",
    "        \n",
    "plotScatter(c1)\n",
    "plotScatter(c2)\n",
    "\n",
    "weights = trainBoundaryHunter()\n",
    "\n",
    "# plt.scatter(weights[1], weights[2])\n",
    "plt.scatter(weights[2], weights[3])\n",
    "\n",
    "n = np.array([weights[0] * weights[2] + weights[1] * weights[3], \n",
    "              -weights[0], \n",
    "              -weights[1]])\n",
    "\n",
    "byas = -1 * n[0]/n[2]\n",
    "Xcoef = -1 * n[1]/n[2]\n",
    "\n",
    "x = np.linspace(-1.5, 1.5, 500)\n",
    "y = np.linspace(-1.5, 1.5, 500)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "F = ((X - weights[2]))**2 + ((Y - weights[3]))**2 - weights[4]**2\n",
    "plt.contour(X,Y,F,[0])\n",
    "\n",
    "print()\n",
    "print(n)\n",
    "print(\"\\nLine\")\n",
    "print(\"B: \" + str(byas))\n",
    "print(\"XCoef: \" + str(Xcoef))\n",
    "\n",
    "plt.plot([-1.0, 1.0], [-1*Xcoef + byas, Xcoef + byas], 'k-')\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
