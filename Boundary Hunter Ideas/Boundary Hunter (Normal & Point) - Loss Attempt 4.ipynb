{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from autograd import grad\n",
    "\n",
    "def generateChevronData():\n",
    "    xBounds = [-50, 50]\n",
    "    yBounds = [-50, 50]\n",
    "    totalPoints = 100\n",
    "    \n",
    "    points = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, totalPoints):\n",
    "        x = random.randint(xBounds[0], xBounds[1])\n",
    "        y = random.randint(yBounds[0], yBounds[1])\n",
    "        \n",
    "        if x >= y and x <= -y:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            points.append([x/50.0,y/50.0])\n",
    "            targets.append(1)\n",
    "        \n",
    "    return np.array(points), np.array(targets)\n",
    "    \n",
    "def plotScatter(points):\n",
    "    xs = [x[0] for x in points]\n",
    "    ys = [y[1] for y in points]\n",
    "    \n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    return 1.0/(1.0 + np.exp(-phi))\n",
    "\n",
    "def loss(weights):\n",
    "    B = 1.35\n",
    "    C = 2.7\n",
    "    \n",
    "    predictions = logisticPrediction(weights, points)\n",
    "    \n",
    "    r = responsibility(weights, points)\n",
    "    \n",
    "    pRight = np.power(predictions, targets) * np.power(1-predictions, 1-targets)\n",
    "    pWrong = np.power(predictions, 1-targets) * np.power(1-predictions, targets)\n",
    "    \n",
    "    return np.sum(r * (B*pRight - C*pWrong))\n",
    "\n",
    "def logisticPrediction(weights, p):\n",
    "    return np.array(list(map(lambda x: predict(weights, x), p))) \n",
    "    \n",
    "def predict(weights, inputs):\n",
    "    n = np.array([weights[0], weights[1]])\n",
    "    i = np.array([weights[2] - inputs[0], weights[3] - inputs[1]])\n",
    "    return sigmoid(np.dot(n, i))\n",
    "\n",
    "def responsibility(weights, points):\n",
    "    r = np.absolute(weights[4])\n",
    "    a = np.array([weights[2], weights[3]])\n",
    "    \n",
    "    dif = np.array(list(map(lambda x: x - a, points)))\n",
    "    s = np.array(list(map(lambda x: np.sum(np.power(x, 2)), dif)))\n",
    "    d = np.sqrt(s)\n",
    "\n",
    "    t = 1 - f(d, r)\n",
    "    return t\n",
    "\n",
    "def f(d, r):  \n",
    "    return 1/(1 + np.power(np.e, -(d-r)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainBoundaryHunter():\n",
    "    weights = np.array([0.0, 0.0, 0.0, 0.0, 0.8])#-0.5 + np.random.rand(5)#\n",
    "    weights[4] = np.absolute(weights[4])\n",
    "    gradient = grad(loss)\n",
    "    print(\"Initial Loss: \", loss(weights))\n",
    "    for i in range(0, 7000):\n",
    "        g = gradient(weights)\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss [i = \" + str(i) + \"]: \" + str(loss(weights)))\n",
    "            print(weights)\n",
    "            checkGrad(0.0001, 0.0001, weights, g)\n",
    "        \n",
    "#         weights = computeStep(weights)\n",
    "        weights += 0.001 * g\n",
    "        if weights[4] < 0:\n",
    "            weights[4] = 0\n",
    "            \n",
    "    print(\"Trained Loss: \", loss(weights))    \n",
    "    print(\"Weights: \", weights)\n",
    "    return weights\n",
    "\n",
    "def checkGrad(pterb, threshold, weights, g):\n",
    "    grad = np.zeros(len(weights))\n",
    "    for i in range(0, len(weights)):\n",
    "        p = np.zeros(len(weights))\n",
    "        p[i] = pterb\n",
    "        \n",
    "        lossBefore = loss(weights)\n",
    "        lossAfter = loss(weights + p)\n",
    "        \n",
    "        grad[i] = (lossAfter - lossBefore)/pterb\n",
    "        \n",
    "\n",
    "    return grad\n",
    "\n",
    "    dif = np.absolute(computedGrad - grad)\n",
    "    for d in dif:\n",
    "        if d > threshold:\n",
    "            print(\"ERROR\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0:  35\n",
      "Type 1:  65\n",
      "Initial Loss:  -33.6158169376\n",
      "Loss [i = 0]: -33.6158169376\n",
      "[ 0.   0.   0.   0.   0.8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/pkg/lib/python3.6/site-packages/autograd/core.py:133: RuntimeWarning: invalid value encountered in true_divide\n",
      "  result = self.fun(*argvals, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "points, targets = generateChevronData()\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "\n",
    "# Plot points on graph\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    if targets[i] == 0:\n",
    "        c1.append(points[i])\n",
    "    else:\n",
    "        c2.append(points[i])\n",
    "\n",
    "print(\"Type 0: \", len(c1))\n",
    "print(\"Type 1: \", len(c2))\n",
    "        \n",
    "plotScatter(c1)\n",
    "plotScatter(c2)\n",
    "\n",
    "random.seed(4332)\n",
    "weights = trainBoundaryHunter()\n",
    "\n",
    "# plt.scatter(weights[1], weights[2])\n",
    "plt.scatter(weights[2], weights[3])\n",
    "\n",
    "n = np.array([weights[0] * weights[2] + weights[1] * weights[3], \n",
    "              -weights[0], \n",
    "              -weights[1]])\n",
    "\n",
    "byas = -1 * n[0]/n[2]\n",
    "Xcoef = -1 * n[1]/n[2]\n",
    "\n",
    "x = np.linspace(-1.5, 1.5, 500)\n",
    "y = np.linspace(-1.5, 1.5, 500)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "F = ((X - weights[2]))**2 + ((Y - weights[3]))**2 - weights[4]**2\n",
    "plt.contour(X,Y,F,[0])\n",
    "\n",
    "print()\n",
    "print(n)\n",
    "print(\"\\nLine\")\n",
    "print(\"B: \" + str(byas))\n",
    "print(\"XCoef: \" + str(Xcoef))\n",
    "\n",
    "plt.plot([-1.0, 1.0], [-1*Xcoef + byas, Xcoef + byas], 'k-')\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
