{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from autograd import grad\n",
    "\n",
    "def generateChevronData():\n",
    "    xBounds = [-50, 50]\n",
    "    yBounds = [-50, 50]\n",
    "    totalPoints = 100\n",
    "    \n",
    "    points = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, totalPoints):\n",
    "        x = random.randint(xBounds[0], xBounds[1])\n",
    "        y = random.randint(yBounds[0], yBounds[1])\n",
    "        \n",
    "        if x >= y and x <= -y:\n",
    "            points.append([1, x/50.0,y/50.0])\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            points.append([1, x/50.0,y/50.0])\n",
    "            targets.append(1)\n",
    "        \n",
    "    return np.array(points), np.array(targets)\n",
    "    \n",
    "def plotScatter(points):\n",
    "    xs = [x[1] for x in points]\n",
    "    ys = [y[2] for y in points]\n",
    "    \n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    return 1.0/(1.0 + np.exp(-phi))\n",
    "\n",
    "def loss(weights):\n",
    "    predictions = logisticPrediction(weights, points)\n",
    "    return 1.0/2.0 * np.sum(np.power((targets - predictions), 2))\n",
    "\n",
    "def logisticPrediction(weights, p):\n",
    "    return np.array(list(map(lambda x: predict(weights, x), p))) \n",
    "    \n",
    "def predict(weights, inputs):\n",
    "    n = np.array([weights[0], weights[1]])\n",
    "    i = np.array([weights[2] - inputs[1], weights[3] - inputs[2]])\n",
    "#     n = np.array([weights[0], weights[1] - weights[3], weights[2] - weights[4]])\n",
    "    return sigmoid(np.dot(n, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeGradient(weights, example, target):\n",
    "    prediction = predict(weights, example)\n",
    "    dE_dO = computeErrorDifferential(prediction, target)\n",
    "    \n",
    "    dO_dZ = prediction * (1-prediction)\n",
    "    \n",
    "#     dZ_d0 = example[0]\n",
    "    dZ_d1 = (weights[2] - example[1])\n",
    "    dZ_d2 = (weights[3] - example[2])\n",
    "    dZ_d3 = weights[0]\n",
    "    dZ_d4 = weights[1]\n",
    "    \n",
    "    dE_dZ = dE_dO * dO_dZ\n",
    "    \n",
    "    grad = np.zeros(len(weights))#[0.0, 0.0, 0.0]\n",
    "#     grad[0] = dZ_d0 * dE_dZ\n",
    "    grad[0] = dZ_d1 * dE_dZ\n",
    "    grad[1] = dZ_d2 * dE_dZ\n",
    "    grad[2] = dZ_d3 * dE_dZ\n",
    "    grad[3] = dZ_d4 * dE_dZ\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def computeErrorDifferential(prediction, target):\n",
    "    return -(target - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBoundaryHunter():\n",
    "    weights = np.array([0.0, 0.0, 0.0, 0.0])\n",
    "    \n",
    "    print(\"Initial Loss: \", MSE(weights))\n",
    "    for i in range(0, 10000):\n",
    "#         g = trainingGradient(weights) * 0.01\n",
    "        if i % 1000 == 0:\n",
    "            print()\n",
    "            print(\"Loss Before: \" + str(MSE(weights)))\n",
    "\n",
    "        weights = computeStep(weights)\n",
    "#         weights -= g\n",
    "    \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss After [i = \" + str(i) + \"]: \" + str(MSE(weights)))\n",
    "            print(weights)\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(weights))    \n",
    "    print(\"Weights: \", weights)\n",
    "    return weights\n",
    "\n",
    "def computeStep(weights):\n",
    "    totalG = np.zeros(len(weights))\n",
    "    totalE = 0\n",
    "    for i in range(0, len(points)):\n",
    "        g = computeGradient(weights, points[i], targets[i])\n",
    "        totalG += g     \n",
    "        \n",
    "#     totalG = totalG * (1/len(points))\n",
    "    \n",
    "    weights -= totalG * 0.01\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0:  35\n",
      "Type 1:  65\n",
      "Initial Loss:  12.5\n",
      "\n",
      "Loss Before: 12.5\n",
      "Loss After [i = 0]: 12.2977334642\n",
      "[-0.00395 -0.04505  0.       0.     ]\n",
      "\n",
      "Loss Before: 4.01012790129\n",
      "Loss After [i = 1000]: 4.00997060309\n",
      "[-1.20492727 -4.91751613 -0.04069226 -0.40726579]\n",
      "\n",
      "Loss Before: 3.93636202462\n",
      "Loss After [i = 2000]: 3.93632991717\n",
      "[-1.46402692 -5.71274349 -0.04051702 -0.40656406]\n",
      "\n",
      "Loss Before: 3.91734039145\n",
      "Loss After [i = 3000]: 3.91732973732\n",
      "[-1.59270233 -6.12357861 -0.04049718 -0.40648712]\n",
      "\n",
      "Loss Before: 3.91041411405\n",
      "Loss After [i = 4000]: 3.91040981763\n",
      "[-1.66916998 -6.37297355 -0.04049606 -0.40648281]\n",
      "\n",
      "Loss Before: 3.90748115692\n",
      "Loss After [i = 5000]: 3.90747923667\n",
      "[-1.71844498 -6.53574047 -0.04049808 -0.40649052]\n",
      "\n",
      "Loss Before: 3.90613150986\n",
      "Loss After [i = 6000]: 3.90613059723\n",
      "[-1.75165442 -6.6463408  -0.04050036 -0.40649917]\n",
      "\n",
      "Loss Before: 3.90547797572\n",
      "Loss After [i = 7000]: 3.90547752455\n",
      "[-1.77466128 -6.72338484 -0.04050229 -0.40650651]\n",
      "\n",
      "Loss Before: 3.90515083764\n",
      "Loss After [i = 8000]: 3.90515060865\n",
      "[-1.79088847 -6.77793206 -0.04050382 -0.40651227]\n",
      "\n",
      "Loss Before: 3.90498336529\n",
      "Loss After [i = 9000]: 3.90498324694\n",
      "[-1.80247349 -6.81697877 -0.04050497 -0.40651665]\n",
      "Trained Loss:  3.90489628601\n",
      "Weights:  [-1.8108071  -6.84512015 -0.04050584 -0.40651993]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a543be1c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "points, targets = generateChevronData()\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "\n",
    "# Plot points on graph\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    if targets[i] == 0:\n",
    "        c1.append(points[i])\n",
    "    else:\n",
    "        c2.append(points[i])\n",
    "\n",
    "print(\"Type 0: \", len(c1))\n",
    "print(\"Type 1: \", len(c2))\n",
    "        \n",
    "plotScatter(c1)\n",
    "plotScatter(c2)\n",
    "\n",
    "weights = trainBoundaryHunter()\n",
    "\n",
    "# plt.scatter(weights[1], weights[2])\n",
    "plt.scatter(weights[2], weights[3])\n",
    "\n",
    "# n = np.array([weights[0] + weights[1] * weights[3] + weights[2] * weights[4], \n",
    "#               -weights[1], \n",
    "#               -weights[2]])\n",
    "\n",
    "# byas = -1 * n[0]/n[2]\n",
    "# Xcoef = -1 * n[1]/n[2]\n",
    "\n",
    "# print()\n",
    "# print(n)\n",
    "# print(\"\\nLine\")\n",
    "# print(\"B: \" + str(byas))\n",
    "# print(\"XCoef: \" + str(Xcoef))\n",
    "\n",
    "# plt.plot([-1.0, 1.0], [-1*Xcoef + byas, Xcoef + byas], 'k-')\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
