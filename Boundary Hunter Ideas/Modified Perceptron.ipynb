{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from autograd import grad\n",
    "\n",
    "def generateChevronData():\n",
    "    xBounds = [-50, 50]\n",
    "    yBounds = [-50, 50]\n",
    "    totalPoints = 100\n",
    "    \n",
    "    points = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, totalPoints):\n",
    "        x = random.randint(xBounds[0], xBounds[1])\n",
    "        y = random.randint(yBounds[0], yBounds[1])\n",
    "        \n",
    "        if x >= y and x <= -y:\n",
    "            points.append([1, x/50.0,y/50.0])\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            points.append([1, x/50.0,y/50.0])\n",
    "            targets.append(1)\n",
    "        \n",
    "    return np.array(points), np.array(targets)\n",
    "    \n",
    "def plotScatter(points):\n",
    "    xs = [x[1] for x in points]\n",
    "    ys = [y[2] for y in points]\n",
    "    \n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    return 1.0/(1.0 + np.exp(-phi))\n",
    "\n",
    "def MSE(weights):\n",
    "    predictions = logisticPrediction(weights, points)\n",
    "    return 1.0/2.0 * np.sum(np.power((targets - predictions), 2))\n",
    "\n",
    "# def localLogLoss(weights):\n",
    "#     predictions = logisticPrediction(weights, points)\n",
    "#     print(targets)\n",
    "#     print(predictions)\n",
    "#     probs = predictions * targets + (1 - predictions) * (1 - targets)\n",
    "#     print(predictions)\n",
    "#     print(targets)\n",
    "#     print(np.log(probs))\n",
    "#     return -(1/len(points)) * np.sum(np.log(probs))\n",
    "\n",
    "# def localLogLoss(weights, example):\n",
    "#     return (predict(weights, example))\n",
    "\n",
    "def logisticPrediction(weights, p):\n",
    "    ins = np.array(list(map(lambda x: predict(weights, x), p)))\n",
    "    return ins\n",
    "    \n",
    "def predict(weights, i):\n",
    "    return sigmoid((i[2] - weights[2]) - weights[0] * (i[1] - weights[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeGradient(weights, example, target):\n",
    "    prediction = predict(weights, example)\n",
    "    E = -np.log(target * prediction + (1-target) * (1-prediction))\n",
    "    dE_dO = computeErrorDifferential(prediction, target)\n",
    "    \n",
    "    dO_dZ = prediction * (1-prediction)\n",
    "    \n",
    "    dZ_dy = -1\n",
    "    dZ_dm = weights[1] - example[1]\n",
    "    dZ_dx = weights[0]\n",
    "    \n",
    "    dE_dZ = dE_dO * dO_dZ\n",
    "    \n",
    "    grad = np.zeros(3)#[0.0, 0.0, 0.0]\n",
    "    grad[0] = dZ_dm * dE_dZ\n",
    "    grad[1] = dZ_dx * dE_dZ\n",
    "    grad[2] = dZ_dy * dE_dZ\n",
    "    \n",
    "    return grad, E\n",
    "\n",
    "def computeErrorDifferential(prediction, target):\n",
    "    return -(target - prediction)\n",
    "#     print(prediction, target)\n",
    "#     if target == 1:\n",
    "#         return -1/np.log(prediction)\n",
    "    \n",
    "#     return 1/np.log(1-prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainBoundaryHunter():\n",
    "    weights = np.array([0.0, 0.0, 1.0])\n",
    "#     trainingGradient = grad(MSE)\n",
    "    \n",
    "    print(\"Initial Loss: \", MSE(weights))\n",
    "    for i in range(0, 5000):\n",
    "#         g = trainingGradient(weights) * 0.01\n",
    "        if i % 1000 == 0:\n",
    "            print()\n",
    "            print(\"Loss Before: \" + str(MSE(weights)))\n",
    "\n",
    "        weights, error = computeStep(weights)\n",
    "#         weights -= g\n",
    "    \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss After [i = \" + str(i) + \"]: \" + str(MSE(weights)))\n",
    "            print(weights)\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(weights))    \n",
    "    print(\"Weights: \", weights)\n",
    "    return weights\n",
    "\n",
    "def computeStep(weights):\n",
    "    totalG = np.zeros(3)\n",
    "    totalE = 0\n",
    "    for i in range(0, len(points)):\n",
    "        g, error = computeGradient(weights, points[i], targets[i])\n",
    "        totalE += error\n",
    "        totalG += g     \n",
    "        \n",
    "    totalG = totalG * (1/len(points))\n",
    "    totalE = totalE * (1/len(points))\n",
    "        \n",
    "    weights -= totalG * 0.01\n",
    "    return weights, totalE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0:  35\n",
      "Type 1:  65\n",
      "Initial Loss:  16.071361585\n",
      "\n",
      "Loss Before: 16.071361585\n",
      "Loss After [i = 0]: 16.0645485641\n",
      "[ -1.09872316e-05   0.00000000e+00   9.99174650e-01]\n",
      "\n",
      "Loss Before: 10.5732644464\n",
      "Loss After [i = 1000]: 10.5695814829\n",
      "[-0.03646671 -0.00977395  0.26200274]\n",
      "\n",
      "Loss Before: 8.38977288885\n",
      "Loss After [i = 2000]: 8.38868256335\n",
      "[-0.10009102 -0.0390594  -0.19243409]\n",
      "\n",
      "Loss Before: 7.78772543189\n",
      "Loss After [i = 3000]: 7.78743922549\n",
      "[-0.15728617 -0.06839966 -0.4243727 ]\n",
      "\n",
      "Loss Before: 7.62870085544\n",
      "Loss After [i = 4000]: 7.62862354172\n",
      "[-0.19982366 -0.0886823  -0.53882979]\n",
      "Trained Loss:  7.58464854532\n",
      "Weights:  [-0.23024284 -0.10075366 -0.59521701]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/9/vhAG3CYzYAAAAAElEQVQ1rwYeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b586a544e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "points, targets = generateChevronData()\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "\n",
    "# Plot points on graph\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    if targets[i] == 0:\n",
    "        c1.append(points[i])\n",
    "    else:\n",
    "        c2.append(points[i])\n",
    "\n",
    "print(\"Type 0: \", len(c1))\n",
    "print(\"Type 1: \", len(c2))\n",
    "        \n",
    "plotScatter(c1)\n",
    "plotScatter(c2)\n",
    "\n",
    "weights = trainBoundaryHunter()\n",
    "plt.scatter(weights[1], weights[2])\n",
    "plt.plot([-1.0, 1.0], [weights[2] + weights[0]*((-1) - weights[1]), weights[2] + weights[0]*(1 - weights[1])], 'k-')\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
