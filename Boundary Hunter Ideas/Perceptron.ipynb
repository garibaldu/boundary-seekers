{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import autograd.numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "from autograd import grad\n",
    "\n",
    "def generateChevronData():\n",
    "    xBounds = [-50, 50]\n",
    "    yBounds = [-50, 50]\n",
    "    totalPoints = 100\n",
    "    \n",
    "    points = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(0, totalPoints):\n",
    "        x = random.randint(xBounds[0], xBounds[1])\n",
    "        y = random.randint(yBounds[0], yBounds[1])\n",
    "        \n",
    "        if x >= y and x <= -y:\n",
    "            points.append([1, x/50.0,y/50.0])\n",
    "            targets.append(0)\n",
    "        else:\n",
    "            points.append([1, x/50.0,y/50.0])\n",
    "            targets.append(1)\n",
    "        \n",
    "    return np.array(points), np.array(targets)\n",
    "    \n",
    "def plotScatter(points):\n",
    "    xs = [x[1] for x in points]\n",
    "    ys = [y[2] for y in points]\n",
    "    \n",
    "    plt.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(phi):\n",
    "    return 1.0/(1.0 + np.exp(-phi))\n",
    "\n",
    "def MSE(weights):\n",
    "    predictions = logisticPrediction(weights, points)\n",
    "    return 1.0/2.0 * np.sum(np.power((targets - predictions), 2))\n",
    "\n",
    "def logisticPrediction(weights, p):\n",
    "    return predict(weights, p)\n",
    "    \n",
    "def predict(weights, inputs):\n",
    "    return sigmoid(np.dot(inputs, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeGradient(weights, example, target):\n",
    "    prediction = predict(weights, example)\n",
    "    dE_dO = computeErrorDifferential(prediction, target)\n",
    "    \n",
    "    dO_dZ = prediction * (1-prediction)\n",
    "    \n",
    "    dZ_d0 = example[0]\n",
    "    dZ_d1 = example[1]\n",
    "    dZ_d2 = example[2]\n",
    "    \n",
    "    dE_dZ = dE_dO * dO_dZ\n",
    "    \n",
    "    grad = np.zeros(3)#[0.0, 0.0, 0.0]\n",
    "    grad[0] = dZ_d0 * dE_dZ\n",
    "    grad[1] = dZ_d1 * dE_dZ\n",
    "    grad[2] = dZ_d2 * dE_dZ\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def computeErrorDifferential(prediction, target):\n",
    "    return -(target - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainBoundaryHunter():\n",
    "    weights = np.array([0.0, 0.0, 0.0])\n",
    "    \n",
    "    print(\"Initial Loss: \", MSE(weights))\n",
    "    for i in range(0, 50000):\n",
    "#         g = trainingGradient(weights) * 0.01\n",
    "        if i % 1000 == 0:\n",
    "            print()\n",
    "            print(\"Loss Before: \" + str(MSE(weights)))\n",
    "\n",
    "        weights = computeStep(weights)\n",
    "#         weights -= g\n",
    "    \n",
    "        if i % 1000 == 0:\n",
    "            print(\"Loss After [i = \" + str(i) + \"]: \" + str(MSE(weights)))\n",
    "            print(weights)\n",
    "            \n",
    "    print(\"Trained Loss: \", MSE(weights))    \n",
    "    print(\"Weights: \", weights)\n",
    "    return weights\n",
    "\n",
    "def computeStep(weights):\n",
    "    totalG = np.zeros(3)\n",
    "    totalE = 0\n",
    "    for i in range(0, len(points)):\n",
    "        g = computeGradient(weights, points[i], targets[i])\n",
    "        totalG += g     \n",
    "        \n",
    "#     totalG = totalG * (1/len(points))\n",
    "    \n",
    "    weights -= totalG * 0.01\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 0:  35\n",
      "Type 1:  65\n",
      "Initial Loss:  12.5\n",
      "\n",
      "Loss Before: 12.5\n",
      "Loss After [i = 0]: 12.1601229227\n",
      "[ 0.0375   0.00395  0.04505]\n",
      "\n",
      "Loss Before: 4.0327324113\n",
      "Loss After [i = 1000]: 4.03255300491\n",
      "[ 1.96195027  1.16639143  4.75820348]\n",
      "\n",
      "Loss Before: 3.94645855567\n",
      "Loss After [i = 2000]: 3.94641942338\n",
      "[ 2.30367262  1.42195545  5.557882  ]\n",
      "\n",
      "Loss Before: 3.92265656135\n",
      "Loss After [i = 3000]: 3.92264271993\n",
      "[ 2.48647718  1.55383724  5.98422667]\n",
      "\n",
      "Loss Before: 3.91340892145\n",
      "Loss After [i = 4000]: 3.91340296967\n",
      "[ 2.60103167  1.63491233  6.25137564]\n",
      "\n",
      "Loss Before: 3.90922846367\n",
      "Loss After [i = 5000]: 3.90922562267\n",
      "[ 2.67822751  1.68891743  6.43147213]\n",
      "\n",
      "Loss Before: 3.90717137096\n",
      "Loss After [i = 6000]: 3.90716992584\n",
      "[ 2.73244227  1.72655771  6.55800519]\n",
      "\n",
      "Loss Before: 3.90610395777\n",
      "Loss After [i = 7000]: 3.90610319142\n",
      "[ 2.7715221   1.75354803  6.64924495]\n",
      "\n",
      "Loss Before: 3.90553012685\n",
      "Loss After [i = 8000]: 3.90552970868\n",
      "[ 2.80018792  1.77327215  6.71618858]\n",
      "\n",
      "Loss Before: 3.90521396202\n",
      "Loss After [i = 9000]: 3.90521372917\n",
      "[ 2.82147191  1.78787735  6.76590324]\n",
      "\n",
      "Loss Before: 3.90503667925\n",
      "Loss After [i = 10000]: 3.90503654769\n",
      "[ 2.83741288  1.79879426  6.80314348]\n",
      "\n",
      "Loss Before: 3.90493599371\n",
      "Loss After [i = 11000]: 3.90493591857\n",
      "[ 2.84942792  1.80701031  6.83121549]\n",
      "\n",
      "Loss Before: 3.90487826914\n",
      "Loss After [i = 12000]: 3.90487822588\n",
      "[ 2.85852635  1.81322497  6.85247497]\n",
      "\n",
      "Loss Before: 3.90484494149\n",
      "Loss After [i = 13000]: 3.90484491644\n",
      "[ 2.8654402   1.81794347  6.86863105]\n",
      "\n",
      "Loss Before: 3.90482559783\n",
      "Loss After [i = 14000]: 3.90482558325\n",
      "[ 2.87070779  1.82153613  6.8809408 ]\n",
      "\n",
      "Loss Before: 3.90481432581\n",
      "Loss After [i = 15000]: 3.9048143173\n",
      "[ 2.87472903  1.82427742  6.89033837]\n",
      "\n",
      "Loss Before: 3.90480773748\n",
      "Loss After [i = 16000]: 3.9048077325\n",
      "[ 2.87780343  1.82637247  6.8975234 ]\n",
      "\n",
      "Loss Before: 3.90480387785\n",
      "Loss After [i = 17000]: 3.90480387493\n",
      "[ 2.88015662  1.82797558  6.90302305]\n",
      "\n",
      "Loss Before: 3.90480161281\n",
      "Loss After [i = 18000]: 3.90480161109\n",
      "[ 2.88195935  1.82920343  6.90723628]\n",
      "\n",
      "Loss Before: 3.90480028178\n",
      "Loss After [i = 19000]: 3.90480028077\n",
      "[ 2.88334129  1.83014452  6.91046613]\n",
      "\n",
      "Loss Before: 3.90479949882\n",
      "Loss After [i = 20000]: 3.90479949822\n",
      "[ 2.88440121  1.83086623  6.91294337]\n",
      "\n",
      "Loss Before: 3.90479903788\n",
      "Loss After [i = 21000]: 3.90479903753\n",
      "[ 2.88521446  1.83141992  6.91484411]\n",
      "\n",
      "Loss Before: 3.90479876637\n",
      "Loss After [i = 22000]: 3.90479876616\n",
      "[ 2.88583863  1.83184485  6.91630294]\n",
      "\n",
      "Loss Before: 3.90479860636\n",
      "Loss After [i = 23000]: 3.90479860624\n",
      "[ 2.88631779  1.83217104  6.91742286]\n",
      "\n",
      "Loss Before: 3.90479851203\n",
      "Loss After [i = 24000]: 3.90479851196\n",
      "[ 2.8866857   1.83242148  6.91828275]\n",
      "\n",
      "Loss Before: 3.9047984564\n",
      "Loss After [i = 25000]: 3.90479845636\n",
      "[ 2.88696822  1.83261379  6.91894308]\n",
      "\n",
      "Loss Before: 3.90479842359\n",
      "Loss After [i = 26000]: 3.90479842357\n",
      "[ 2.8871852   1.83276148  6.91945021]\n",
      "\n",
      "Loss Before: 3.90479840424\n",
      "Loss After [i = 27000]: 3.90479840423\n",
      "[ 2.88735185  1.83287491  6.91983971]\n",
      "\n",
      "Loss Before: 3.90479839282\n",
      "Loss After [i = 28000]: 3.90479839281\n",
      "[ 2.88747985  1.83296204  6.92013889]\n",
      "\n",
      "Loss Before: 3.90479838608\n",
      "Loss After [i = 29000]: 3.90479838608\n",
      "[ 2.88757818  1.83302897  6.92036871]\n",
      "\n",
      "Loss Before: 3.90479838211\n",
      "Loss After [i = 30000]: 3.90479838211\n",
      "[ 2.8876537   1.83308037  6.92054524]\n",
      "\n",
      "Loss Before: 3.90479837976\n",
      "Loss After [i = 31000]: 3.90479837976\n",
      "[ 2.88771173  1.83311987  6.92068085]\n",
      "\n",
      "Loss Before: 3.90479837838\n",
      "Loss After [i = 32000]: 3.90479837838\n",
      "[ 2.8877563   1.8331502   6.92078503]\n",
      "\n",
      "Loss Before: 3.90479837756\n",
      "Loss After [i = 33000]: 3.90479837756\n",
      "[ 2.88779054  1.83317351  6.92086506]\n",
      "\n",
      "Loss Before: 3.90479837708\n",
      "Loss After [i = 34000]: 3.90479837708\n",
      "[ 2.88781684  1.83319141  6.92092654]\n",
      "\n",
      "Loss Before: 3.90479837679\n",
      "Loss After [i = 35000]: 3.90479837679\n",
      "[ 2.88783705  1.83320517  6.92097377]\n",
      "\n",
      "Loss Before: 3.90479837663\n",
      "Loss After [i = 36000]: 3.90479837663\n",
      "[ 2.88785258  1.83321573  6.92101006]\n",
      "\n",
      "Loss Before: 3.90479837653\n",
      "Loss After [i = 37000]: 3.90479837653\n",
      "[ 2.8878645   1.83322385  6.92103793]\n",
      "\n",
      "Loss Before: 3.90479837647\n",
      "Loss After [i = 38000]: 3.90479837647\n",
      "[ 2.88787367  1.83323009  6.92105935]\n",
      "\n",
      "Loss Before: 3.90479837643\n",
      "Loss After [i = 39000]: 3.90479837643\n",
      "[ 2.8878807   1.83323488  6.9210758 ]\n",
      "\n",
      "Loss Before: 3.90479837641\n",
      "Loss After [i = 40000]: 3.90479837641\n",
      "[ 2.88788611  1.83323856  6.92108844]\n",
      "\n",
      "Loss Before: 3.9047983764\n",
      "Loss After [i = 41000]: 3.9047983764\n",
      "[ 2.88789027  1.83324139  6.92109815]\n",
      "\n",
      "Loss Before: 3.90479837639\n",
      "Loss After [i = 42000]: 3.90479837639\n",
      "[ 2.88789346  1.83324356  6.92110561]\n",
      "\n",
      "Loss Before: 3.90479837639\n",
      "Loss After [i = 43000]: 3.90479837639\n",
      "[ 2.88789591  1.83324523  6.92111134]\n",
      "\n",
      "Loss Before: 3.90479837639\n",
      "Loss After [i = 44000]: 3.90479837639\n",
      "[ 2.8878978   1.83324651  6.92111575]\n",
      "\n",
      "Loss Before: 3.90479837639\n",
      "Loss After [i = 45000]: 3.90479837639\n",
      "[ 2.88789924  1.83324749  6.92111913]\n",
      "\n",
      "Loss Before: 3.90479837639\n",
      "Loss After [i = 46000]: 3.90479837639\n",
      "[ 2.88790035  1.83324825  6.92112173]\n",
      "\n",
      "Loss Before: 3.90479837638\n",
      "Loss After [i = 47000]: 3.90479837638\n",
      "[ 2.88790121  1.83324883  6.92112372]\n",
      "\n",
      "Loss Before: 3.90479837638\n",
      "Loss After [i = 48000]: 3.90479837638\n",
      "[ 2.88790186  1.83324928  6.92112526]\n",
      "\n",
      "Loss Before: 3.90479837638\n",
      "Loss After [i = 49000]: 3.90479837638\n",
      "[ 2.88790237  1.83324962  6.92112644]\n",
      "Trained Loss:  3.90479837638\n",
      "Weights:  [ 2.88790276  1.83324989  6.92112734]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aeff71c668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "points, targets = generateChevronData()\n",
    "\n",
    "plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "\n",
    "# Plot points on graph\n",
    "c1 = []\n",
    "c2 = []\n",
    "\n",
    "for i in range(0, len(points)):\n",
    "    if targets[i] == 0:\n",
    "        c1.append(points[i])\n",
    "    else:\n",
    "        c2.append(points[i])\n",
    "\n",
    "print(\"Type 0: \", len(c1))\n",
    "print(\"Type 1: \", len(c2))\n",
    "        \n",
    "plotScatter(c1)\n",
    "plotScatter(c2)\n",
    "\n",
    "weights = trainBoundaryHunter()\n",
    "byas = -1 * weights[0]/weights[2]\n",
    "Xcoef = -1 * weights[1]/weights[2]\n",
    "plt.plot([-1.0, 1.0], [-1*Xcoef + byas, Xcoef + byas], 'k-')\n",
    "plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
